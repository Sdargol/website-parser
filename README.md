### Описание проекта
Приложение, которое может загружать произвольную страницу из интернета и сохранять на компьютер, после чего производит разбор страницы (считает уникальные слова) и формирует отчет в виде “СЛОВО” – СКОЛЬКО РАЗ ВСТРЕЧАЕТСЯ.

### Инструкция по запуску
Данное приложение разрабатывалось и тестировалось в intellij idea community edition, версия Java openjdk 15, Spring Boot 2.5.0-SNAPSHOT, PostgreSQL 13. После того, как вы клонируете репозиторий, необходимо установить зависимости (для удобства, клиент уже скомпилирован и находится в ресурсах Java проекта, поэтому устанавливать зависимости фронтенда нет необходимости, если не планируется его запуск отдельно). Прежде чем запустить проект, необходимо создать таблицы в бд (код SQL запросов находится в файле db.sql), а также настроить application.properties (подключение к бд). Затем можно запускать проект, он автоматически создаст папки download и logs.

### Принцип работы
Для того, чтобы попасть на главную страницу веб клиента, необходимо после запуска приложения открыть браузер и перейти по следующей ссылке - http://localhost:8080/, после чего в поле url ввести ссылку на сайт, нажать кнопку START, после чего приложение начнет загрузку и разбор сайта (необходимо обновиться страницу, чтобы результат работы отобразился на странице). В случае удачного разбора, нажав на ссылку в колонке “url сайта” мы попадем на страницу со статистикой.

### Заметки
Статистика по словам сохраняется в базу данных, но в двоичном формате одним файлом. Сделано это по той причине, что в среднем обычные (например, новостные) сайты содержат примерно 600 – 1000 слов, и я посчитал, что будет как-то неразумно, если один запрос на парсинг будет создавать такое число записей в базе. Поэтому приложение занимается всей необходимой конвертацией для хранения и передачи фронтенду данных. Работа по загрузке и обработке исполняется в отдельном потоке (за это отвечает ThreadPoolTaskExecutor), таким образом запрос на парсинг не “подвисает”.  Приложение логирует шаги обработки для наглядности. В коде присутствуют также комментарии в некоторых местах, которые могут вызвать интерес. Можно также через браузер обраться к загруженным файлам по пути /download/имя_файла_на_диске (этот момент на фронтенде не реализовал, но нужное имя приходит в ответах и доступно по имени urlGetFile, оно короче совпадает с именем файла в папке download, можно ещё в бд глянуть че да как).

### API
POST `/api/v1/parser` тело запроса: {url : “https://имя_сайта_типо”} создает задачу на парсинг. 
GET `/api/v1/parser` вернет ResponseEntity<List<SiteDTOBase>> краткую информацию о сайтах.
GET `/api/v1/parser/{id}` вернет ResponseEntity<SiteDTO> подробную информацию о сайте.
DELETE `/api/v1/parser/{id}` удалит сущность и вернет Integer id удаленного сайта.

### Вывод
В целом, в рамках данного приложения удалось решить поставленную задачу – оно работает и ладно =). Есть места, которые можно улучшить и доработать, но на данный момент на протестированных сайтах все работает гладко (результат сравнивал с поиском по исходному коду страницы).
